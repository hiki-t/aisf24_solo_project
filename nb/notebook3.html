
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Experiment 3 &#8212; My sample book</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!-- 
    this give us a css class that will be invisible only if js is disabled 
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b76e3c8a" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- So that users can add custom icons -->
  <script src="../_static/scripts/fontawesome.js?digest=26a4bc78f4c0ddb94549"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549" />

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'nb/notebook3';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="prev" title="Experiment 2" href="notebook2.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="My sample book - Home"/>
    <img src="../_static/logo.png" class="logo__image only-dark pst-js-only" alt="My sample book - Home"/>
  
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Welcome to my AI safety project
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">My work</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="notebook1.html">Exp1</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebook2.html">Exp2</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Exp3</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Fnb/notebook3.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/nb/notebook3.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Experiment 3</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exp3">Exp3</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exp3-0-prepare-packages">Exp3.0. Prepare packages</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exp3-1-run-first-exp">Exp3.1. Run first exp</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exp3-2-result">Exp3.2. Result</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exp3-3-run-second-exp">Exp3.3. Run second exp</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exp3-4-result">Exp3.4. Result</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="experiment-3">
<h1>Experiment 3<a class="headerlink" href="#experiment-3" title="Link to this heading">#</a></h1>
<p><br><br></p>
<section id="exp3">
<h2>Exp3<a class="headerlink" href="#exp3" title="Link to this heading">#</a></h2>
<p>As Exp 1-2 demonstrated superposition in the Linear model with ReLU filter using the MNIST handwritten digit image dataset when high sparsity level is set (e.g. 0.999), the next step is to test if a SAE model represents monosemantic-like features (each or a few neurons representing a particular feature) of the handwritten digit datasets when the dataset is set with large sparsity level (e.g. 0.999).</p>
<ol class="arabic simple">
<li><p>The first exp will test to replicate one of the <a class="reference external" href="https://transformer-circuits.pub/2023/monosemantic-features/index.html">Anthropic research outcome (Bricken et al., 2023)</a> (see the activation historgram in the diagram below), demonstrating that a or a few specific neurons is only activated to a specific input (the below example demonstrating sensitive responds of neuron-489 to “a mixture of different non-English languages” inputs). Thus, this exp will assess if only a small portion of neurons will be activated to each digit image.</p></li>
<li><p>Once the first exp is successful, the second exp will test if purely activating specific features alone will reconstruct these specific inputs (e.g. only activating feature- or neuron-1 will reconstruct an image of digit 0).</p></li>
</ol>
<br>
<p><img alt="img title" src="../_images/exp3_diagram2.png" /></p>
<br>
<p>To make more specifics, I will test two directions in Exp3 (see the below diagram for visual summary),</p>
<ul class="simple">
<li><p>The 1st exp (the brown rectangle boxes):</p>
<ul>
<li><p>a toy model is the same Linear model with one hidden layer (49 dim) and a ReLU filtering function.</p></li>
<li><p>decomposing features from the original dim (49 dim) into a larger dim (49*2 dim) with varied sparsity level (0.1 vs 0.999) via sparse autoencoder (SAE) model.</p></li>
<li><p>if small sparsity level is set (0.1), feature representations will be limited with a fewer neurons,</p>
<ul>
<li><p>which is demonstrated by activation histogram (like the above diagram) with a larger tail at low activation and only a few neurons with large activation for each digit. <a class="reference internal" href="#Figure-1"><span class="xref myst">(Figure 1)</span></a></p></li>
</ul>
</li>
<li><p>if high sparsity level is set (0.999), feature representations will be more spread across neurons,</p>
<ul>
<li><p>which is demonstrated by activation histogram with a smaller tail at low activation and more neurons with midium to large activation for each digit. <a class="reference internal" href="#Figure-2"><span class="xref myst">(Figure 2)</span></a></p></li>
</ul>
</li>
</ul>
</li>
<li><p>The 2nd exp (the orange rectangle box):</p>
<ul>
<li><p>training the gen model (49 dim) with features of the original hidden layer (49 dim) and the MNIST digit image datasets and test if activation of the hidden layer feature alone can reconstruct the original images with the gen model. <a class="reference internal" href="#Figure-3"><span class="xref myst">(Figure 3)</span></a></p></li>
</ul>
</li>
</ul>
<p><br><br></p>
<p><img alt="img title" src="../_images/exp3_diagram1.png" /></p>
<p><br><br></p>
</section>
<section id="exp3-0-prepare-packages">
<h2>Exp3.0. Prepare packages<a class="headerlink" href="#exp3-0-prepare-packages" title="Link to this heading">#</a></h2>
<p><br><br></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">### import packages </span>

<span class="c1"># ml/nn</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>  <span class="c1"># all neural network modules</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>  <span class="c1"># Functions with no parameters -&gt; activation functions</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>  <span class="c1"># optimization algo</span>

<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">Dataset</span> <span class="c1"># easier dataset management, helps create mini batches</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">random_split</span> <span class="c1"># set train-test ratio</span>

<span class="c1"># import torchvision</span>
<span class="kn">import</span> <span class="nn">torchvision.datasets</span> <span class="k">as</span> <span class="nn">datasets</span>  <span class="c1"># standard datasets</span>
<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="nn">transforms</span> <span class="c1"># this for convert dataset to tensor</span>
<span class="kn">from</span> <span class="nn">torchvision.utils</span> <span class="kn">import</span> <span class="n">make_grid</span> <span class="c1"># this for visualization</span>

<span class="c1"># stats/ml #1</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib.offsetbox</span> <span class="kn">import</span> <span class="n">OffsetImage</span><span class="p">,</span> <span class="n">AnnotationBbox</span>

<span class="c1"># stats/ml #2</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">decomposition</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">manifold</span>
<span class="kn">from</span> <span class="nn">sklearn.manifold</span> <span class="kn">import</span> <span class="n">TSNE</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics.pairwise</span> <span class="kn">import</span> <span class="n">cosine_distances</span>

<span class="kn">import</span> <span class="nn">random</span>
</pre></div>
</div>
</div>
</div>
<p><br><br></p>
</section>
<section id="exp3-1-run-first-exp">
<h2>Exp3.1. Run first exp<a class="headerlink" href="#exp3-1-run-first-exp" title="Link to this heading">#</a></h2>
<p><br><br></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">### set device</span>

<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>cpu
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">### define original functions</span>

<span class="c1"># Function to add an image at each point</span>
<span class="k">def</span> <span class="nf">add_image</span><span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="n">img</span><span class="p">,</span> <span class="n">xy</span><span class="p">,</span> <span class="n">zoom</span><span class="o">=</span><span class="mf">0.3</span><span class="p">):</span>
    <span class="n">imagebox</span> <span class="o">=</span> <span class="n">OffsetImage</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">zoom</span><span class="o">=</span><span class="n">zoom</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>  <span class="c1"># Use `cmap` for grayscale images</span>
    <span class="n">ab</span> <span class="o">=</span> <span class="n">AnnotationBbox</span><span class="p">(</span><span class="n">imagebox</span><span class="p">,</span> <span class="n">xy</span><span class="p">,</span> <span class="n">frameon</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">add_artist</span><span class="p">(</span><span class="n">ab</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">### Define all parameters</span>

<span class="c1"># later these will be inserted at the beginning as args</span>

<span class="c1"># fixed</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">input_size</span> <span class="o">=</span> <span class="mi">784</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="mi">10</span>

<span class="c1"># variable</span>
<span class="n">hidden_size</span> <span class="o">=</span> <span class="mi">49</span> <span class="c1"># for lin model</span>
<span class="n">hidden_size2</span> <span class="o">=</span> <span class="mi">49</span><span class="o">*</span><span class="mi">4</span> <span class="c1"># for sae hidden dim</span>
<span class="n">lr1</span> <span class="o">=</span> <span class="mf">0.001</span>
<span class="n">lr2</span> <span class="o">=</span> <span class="mf">0.0001</span>
<span class="n">lr3</span> <span class="o">=</span> <span class="mf">0.0001</span>

<span class="c1"># when sparsity lv is close to 0, feature is dense</span>
<span class="n">sparsity_lv</span> <span class="o">=</span> <span class="mf">0.1</span> <span class="c1"># vary sparsity level from 0.001-0.999</span>
<span class="n">sparsity_impact</span> <span class="o">=</span> <span class="mf">1e-4</span> <span class="c1"># 1e-4 # </span>
<span class="n">eps</span> <span class="o">=</span> <span class="mf">1e-7</span> <span class="c1"># epsilon</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Function to scramble MNIST images</span>
<span class="k">def</span> <span class="nf">scramble_batch_images</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">block_size</span><span class="o">=</span><span class="mi">4</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Scrambles a batch of images into blocks of block_size x block_size.&quot;&quot;&quot;</span>
    <span class="n">batch_size</span><span class="p">,</span> <span class="n">channels</span><span class="p">,</span> <span class="n">height</span><span class="p">,</span> <span class="n">width</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
    <span class="k">assert</span> <span class="n">channels</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">height</span> <span class="o">==</span> <span class="mi">28</span> <span class="ow">and</span> <span class="n">width</span> <span class="o">==</span> <span class="mi">28</span><span class="p">,</span> <span class="s2">&quot;Only supports MNIST-sized images with 1 channel.&quot;</span>
    
    <span class="n">num_blocks</span> <span class="o">=</span> <span class="n">height</span> <span class="o">//</span> <span class="n">block_size</span>  <span class="c1"># Number of blocks along one dimension</span>
    <span class="n">scrambled_images</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>  <span class="c1"># Prepare output tensor</span>
    
    <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">):</span>
        <span class="n">img</span> <span class="o">=</span> <span class="n">images</span><span class="p">[</span><span class="n">b</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>  <span class="c1"># Extract single image, shape [28, 28]</span>
        <span class="n">scrambled_img</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
        
        <span class="c1"># Define block indices</span>
        <span class="n">block_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">num_blocks</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">num_blocks</span><span class="p">,</span> <span class="n">num_blocks</span><span class="p">)</span>
        <span class="n">flat_indices</span> <span class="o">=</span> <span class="n">block_indices</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
        <span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">flat_indices</span><span class="p">)</span>  <span class="c1"># Shuffle the indices</span>
        
        <span class="c1"># Rearrange blocks based on shuffled indices</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_blocks</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_blocks</span><span class="p">):</span>
                <span class="n">src_idx</span> <span class="o">=</span> <span class="nb">divmod</span><span class="p">(</span><span class="n">flat_indices</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">num_blocks</span><span class="p">)</span>
                <span class="n">src_i</span><span class="p">,</span> <span class="n">src_j</span> <span class="o">=</span> <span class="n">src_idx</span>
                <span class="n">scrambled_img</span><span class="p">[</span><span class="n">i</span><span class="o">*</span><span class="n">block_size</span><span class="p">:(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">block_size</span><span class="p">,</span> <span class="n">j</span><span class="o">*</span><span class="n">block_size</span><span class="p">:(</span><span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">block_size</span><span class="p">]</span> <span class="o">=</span> \
                    <span class="n">img</span><span class="p">[</span><span class="n">src_i</span><span class="o">*</span><span class="n">block_size</span><span class="p">:(</span><span class="n">src_i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">block_size</span><span class="p">,</span> <span class="n">src_j</span><span class="o">*</span><span class="n">block_size</span><span class="p">:(</span><span class="n">src_j</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">block_size</span><span class="p">]</span>
                <span class="n">idx</span> <span class="o">+=</span> <span class="mi">1</span>
        
        <span class="n">scrambled_images</span><span class="p">[</span><span class="n">b</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">scrambled_img</span>  <span class="c1"># Save the scrambled image back</span>
    
    <span class="k">return</span> <span class="n">scrambled_images</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create a dataset of scrambled images with incorrect labels</span>
<span class="k">class</span> <span class="nc">ScrambledMNISTDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">original_dataset</span><span class="p">,</span> <span class="n">block_size</span><span class="o">=</span><span class="mi">4</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">original_dataset</span> <span class="o">=</span> <span class="n">original_dataset</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">block_size</span> <span class="o">=</span> <span class="n">block_size</span>
    
    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">original_dataset</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="n">original_image</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">original_dataset</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>  <span class="c1"># Ignore original label</span>
        <span class="n">scrambled_image</span> <span class="o">=</span> <span class="n">scramble_batch_images</span><span class="p">(</span><span class="n">original_image</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">block_size</span><span class="p">)</span>  <span class="c1"># Add batch dimension</span>
        
        <span class="c1"># Assign an incorrect label</span>
        <span class="n">incorrect_label</span> <span class="o">=</span> <span class="mi">10</span>  <span class="c1"># A label outside the range 0-9</span>
        
        <span class="k">return</span> <span class="n">scrambled_image</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">incorrect_label</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">### define datasets</span>

<span class="c1"># load dataset</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">&#39;../dataset/&#39;</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">&#39;../dataset/&#39;</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Create the scrambled dataset</span>
<span class="n">block_size</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">scrambled_train</span> <span class="o">=</span> <span class="n">ScrambledMNISTDataset</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">block_size</span><span class="p">)</span>
<span class="n">scrambled_test</span> <span class="o">=</span> <span class="n">ScrambledMNISTDataset</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">,</span> <span class="n">block_size</span><span class="p">)</span>

<span class="c1"># Combine original and scrambled datasets into a single DataLoader</span>
<span class="n">combined_train</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">ConcatDataset</span><span class="p">([</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">scrambled_train</span><span class="p">])</span>
<span class="n">combined_test</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">ConcatDataset</span><span class="p">([</span><span class="n">test_dataset</span><span class="p">,</span> <span class="n">scrambled_test</span><span class="p">])</span>

<span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">combined_train</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">test_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">combined_test</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># when add scrambled</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="mi">11</span>

<span class="c1"># # classic way</span>
<span class="c1"># train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)</span>
<span class="c1"># test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">### implement single layer linear (MLP) model, classic autoencoder model, sparse autoencoder model</span>

<span class="c1"># sparse autoencoder (SAE)</span>
<span class="k">class</span> <span class="nc">sae_model</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">sparsity_lambda</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span> <span class="n">sparsity_target</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">sae_model</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">encoder</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">decoder</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sparsity_lambda</span> <span class="o">=</span> <span class="n">sparsity_lambda</span> <span class="c1"># sparsity penalty impact</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sparsity_target</span> <span class="o">=</span> <span class="n">sparsity_target</span> <span class="c1"># target sparsity distribution</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="n">epsilon</span>

        <span class="c1"># paper said, initialization use the Kaiming Uniform initialization</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">kaiming_uniform_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">fc_enc</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">fc_enc</span><span class="o">.</span><span class="n">bias</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        
        <span class="c1"># paper said, initialization use the Kaiming Uniform initialization</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">kaiming_uniform_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">fc_dec</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">fc_dec</span><span class="o">.</span><span class="n">bias</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">encoded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">fc_dec</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>
        <span class="n">decoded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">encoded</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">decoded</span><span class="p">,</span> <span class="n">encoded</span>

    <span class="c1"># paper said used sum, but I will explore with kl divergence</span>
    <span class="k">def</span> <span class="nf">sparsity_penalty</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encoded</span><span class="p">):</span>
        <span class="n">rho_hat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">encoded</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">rho</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sparsity_target</span>
        <span class="n">epsilon</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span>
        <span class="n">rho_hat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">rho_hat</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="n">epsilon</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">1</span> <span class="o">-</span> <span class="n">epsilon</span><span class="p">)</span>
        <span class="n">kl_divergence</span> <span class="o">=</span> <span class="n">rho</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">rho</span> <span class="o">/</span> <span class="n">rho_hat</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">rho</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">((</span><span class="mi">1</span> <span class="o">-</span> <span class="n">rho</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">rho_hat</span><span class="p">))</span>
        <span class="n">sparsity_penalty</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">kl_divergence</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">sparsity_lambda</span> <span class="o">*</span> <span class="n">sparsity_penalty</span>
    
    <span class="k">def</span> <span class="nf">loss_function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_hat</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">encoded</span><span class="p">):</span>
        <span class="n">mse_loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">mse_loss</span><span class="p">(</span><span class="n">x_hat</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
        <span class="n">sparsity_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sparsity_penalty</span><span class="p">(</span><span class="n">encoded</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">mse_loss</span> <span class="o">+</span> <span class="n">sparsity_loss</span>

<span class="c1"># encoder net/layer for sae</span>
<span class="k">class</span> <span class="nc">encoderNN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">encoderNN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc_enc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">pre_bias</span><span class="p">):</span>
        <span class="c1"># follow the Anthropic SAE setup</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">-</span> <span class="n">pre_bias</span> <span class="c1"># pre-encoder bias</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc_enc</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="c1"># 49-&gt; 49xn dim</span>
        <span class="c1"># x = torch.tanh(x) # range [-1:1] as similar operations as previous exp</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="c1"># decoder net/layer for sae</span>
<span class="k">class</span> <span class="nc">decoderNN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">decoderNN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc_dec</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc_dec</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="c1"># 49xn dim -&gt; 49(orig)</span>
        <span class="c1"># x = torch.tanh(x) # range [-1:1]</span>
        <span class="c1"># x = F.relu(x) # range [0:1] as lin model</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="c1"># lin model</span>
<span class="k">class</span> <span class="nc">lin_model</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">):</span>  
        <span class="nb">super</span><span class="p">(</span><span class="n">lin_model</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span> <span class="c1"># input: 28x28=784, hidden: 7x7=49</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span> <span class="c1"># hidden: 49, num_classes: 10</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="c1"># 784 -&gt; 49</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="c1"># range [-1:1]</span>
        <span class="n">x_h</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="c1"># add non-linearity [0:1]</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x_h</span><span class="p">)</span> <span class="c1"># 49-&gt;10</span>
        <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">x_h</span>

<span class="c1"># reconstruct original image</span>
<span class="k">class</span> <span class="nc">ae4img_gen</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ae4img_gen</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># self.fc1 = nn.Linear(input_size, hidden_size) # input: 784, target_dim: 49</span>
        <span class="c1"># self.fc2 = nn.Linear(hidden_size, input_size) # reconstruct image 784</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">input_size</span><span class="p">)</span> <span class="c1"># reconstruct image 784</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># x = self.fc1(x) # 784-&gt;49</span>
        <span class="c1"># x = torch.tanh(x) # range within [-1:1]</span>
        <span class="c1"># x_h = F.relu(x) # add non-linearity</span>
        <span class="c1"># x = self.fc2(x_h) # 49-&gt;784</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="c1"># 49-&gt;784</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="c1"># range within [0:1] as orig image is 0-1</span>
        <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">### initialize model, loss, optimizer</span>

<span class="c1"># linear</span>
<span class="n">m1</span> <span class="o">=</span> <span class="n">lin_model</span><span class="p">(</span>
    <span class="n">input_size</span><span class="o">=</span><span class="n">input_size</span><span class="p">,</span> <span class="c1"># 784</span>
    <span class="n">hidden_size</span><span class="o">=</span><span class="n">hidden_size</span><span class="p">,</span> <span class="c1"># 49</span>
    <span class="n">num_classes</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="c1"># 10</span>
<span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># encoder/decoder nets</span>
<span class="n">enc_m</span> <span class="o">=</span> <span class="n">encoderNN</span><span class="p">(</span><span class="n">input_size</span><span class="o">=</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="o">=</span><span class="n">hidden_size2</span><span class="p">)</span> <span class="c1"># 49 -&gt; 49*n</span>
<span class="n">dec_m</span> <span class="o">=</span> <span class="n">decoderNN</span><span class="p">(</span><span class="n">hidden_size</span><span class="o">=</span><span class="n">hidden_size2</span><span class="p">,</span> <span class="n">output_size</span><span class="o">=</span><span class="n">hidden_size</span><span class="p">)</span> <span class="c1"># 49*n -&gt; 49</span>

<span class="c1"># sae</span>
<span class="n">m2</span> <span class="o">=</span> <span class="n">sae_model</span><span class="p">(</span>
    <span class="n">encoder</span><span class="o">=</span><span class="n">enc_m</span><span class="p">,</span> <span class="n">decoder</span><span class="o">=</span><span class="n">dec_m</span><span class="p">,</span> 
    <span class="n">sparsity_lambda</span><span class="o">=</span><span class="n">sparsity_impact</span><span class="p">,</span> 
    <span class="n">sparsity_target</span><span class="o">=</span><span class="n">sparsity_lv</span><span class="p">,</span> 
    <span class="n">epsilon</span><span class="o">=</span><span class="n">eps</span>
<span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># imageGen</span>
<span class="n">m3</span> <span class="o">=</span> <span class="n">ae4img_gen</span><span class="p">(</span>
    <span class="n">input_size</span><span class="o">=</span><span class="n">input_size</span><span class="p">,</span> <span class="c1"># 784</span>
    <span class="n">hidden_size</span><span class="o">=</span><span class="n">hidden_size</span><span class="p">,</span> <span class="c1"># 49</span>
<span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># Loss</span>
<span class="n">criterion1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span> <span class="c1"># lin</span>
<span class="c1"># criterion2 = nn.MSELoss() # sae</span>
<span class="n">criterion3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span> <span class="c1"># img gen</span>

<span class="c1"># Optimizer</span>
<span class="n">opt1</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">m1</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr1</span><span class="p">)</span>
<span class="n">opt2</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">m2</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr2</span><span class="p">)</span>
<span class="n">opt3</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">m3</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr3</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">### train and validaiton</span>

<span class="c1"># phase 1: train lin/cnn models to predict hand-written digit classes</span>
<span class="k">def</span> <span class="nf">phase1</span><span class="p">(</span><span class="n">model1</span><span class="p">,</span> <span class="n">criterion1</span><span class="p">,</span> <span class="n">opt1</span><span class="p">,</span> <span class="n">epo_n</span><span class="p">):</span>
    <span class="c1"># training</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epo_n</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
            <span class="c1"># reshape [batch, 1, 28,28] to [batch, 28*28]</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    
            <span class="c1"># Step 1: Forward pass through model1</span>
            <span class="n">out1</span><span class="p">,</span> <span class="n">h1</span> <span class="o">=</span> <span class="n">model1</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="c1"># out1:[batch, 10] as 10 class, h1:[batch, 49] as 49 latent</span>
            <span class="c1"># Step 2: Compute loss1 and update model1</span>
            <span class="n">loss1</span> <span class="o">=</span> <span class="n">criterion1</span><span class="p">(</span><span class="n">out1</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
            
            <span class="n">opt1</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">loss1</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">opt1</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    
        <span class="n">num_correct</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">num_samples</span> <span class="o">=</span> <span class="mi">0</span>
        
        <span class="c1"># validation</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">test_loader</span><span class="p">):</span>
                <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">out1</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">model1</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
                <span class="n">_</span><span class="p">,</span> <span class="n">predictions</span> <span class="o">=</span> <span class="n">out1</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">num_correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">predictions</span> <span class="o">==</span> <span class="n">targets</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
                <span class="n">num_samples</span> <span class="o">+=</span> <span class="n">predictions</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    
            <span class="n">accuracy</span> <span class="o">=</span> <span class="n">num_correct</span><span class="o">/</span><span class="n">num_samples</span>
        
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epoch [</span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">epo_n</span><span class="si">}</span><span class="s2">], loss: </span><span class="si">{</span><span class="n">loss1</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># phase 2: train sae models to reconstruct trained hidden layer</span>
<span class="k">def</span> <span class="nf">phase2</span><span class="p">(</span><span class="n">model1</span><span class="p">,</span> <span class="n">model2</span><span class="p">,</span> <span class="n">opt2</span><span class="p">,</span> <span class="n">epo_n</span><span class="p">):</span>
    <span class="c1"># training</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epo_n</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
            <span class="c1"># reshape [batch, 1, 28,28] to [batch, 28*28]</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="n">_</span><span class="p">,</span> <span class="n">h1</span> <span class="o">=</span> <span class="n">model1</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="c1"># out1:[batch, 10] as 10 class, h1:[batch, 49] as 49 latent</span>
                <span class="n">h1_clone</span> <span class="o">=</span> <span class="n">h1</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
            
            <span class="n">h1_hat</span><span class="p">,</span> <span class="n">h2</span> <span class="o">=</span> <span class="n">model2</span><span class="p">(</span><span class="n">h1_clone</span><span class="p">)</span>  <span class="c1"># 49 -&gt; 49*2 -&gt; 49</span>
            <span class="n">loss2</span> <span class="o">=</span> <span class="n">model2</span><span class="o">.</span><span class="n">loss_function</span><span class="p">(</span><span class="n">h1_hat</span><span class="p">,</span> <span class="n">h1_clone</span><span class="p">,</span> <span class="n">h2</span><span class="p">)</span>
            <span class="n">opt2</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">loss2</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">opt2</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        
        <span class="c1"># validation</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">losses</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">test_loader</span><span class="p">):</span>
                <span class="n">batch_weight</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">/</span><span class="n">batch_size</span>
                <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">_</span><span class="p">,</span> <span class="n">h1v</span> <span class="o">=</span> <span class="n">model1</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
                <span class="n">h1v_hat</span><span class="p">,</span> <span class="n">h2v</span> <span class="o">=</span> <span class="n">model2</span><span class="p">(</span><span class="n">h1v</span><span class="p">)</span>
                <span class="n">loss2v</span> <span class="o">=</span> <span class="n">model2</span><span class="o">.</span><span class="n">loss_function</span><span class="p">(</span><span class="n">h1v_hat</span><span class="p">,</span> <span class="n">h1v</span><span class="p">,</span> <span class="n">h2v</span><span class="p">)</span><span class="o">*</span><span class="n">batch_weight</span>
                <span class="n">losses</span> <span class="o">+=</span> <span class="n">loss2v</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                <span class="n">count</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">losses</span> <span class="o">=</span> <span class="n">losses</span><span class="o">/</span><span class="n">count</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epoch [</span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">epo_n</span><span class="si">}</span><span class="s2">], loss-val: </span><span class="si">{</span><span class="n">losses</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># phase 3: train img gen models to reconstruct images from trained hidden layer</span>
<span class="k">def</span> <span class="nf">phase3</span><span class="p">(</span><span class="n">model1</span><span class="p">,</span> <span class="n">model3</span><span class="p">,</span> <span class="n">criterion3</span><span class="p">,</span> <span class="n">opt3</span><span class="p">,</span> <span class="n">epo_n</span><span class="p">):</span>
    <span class="c1"># training</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epo_n</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
            <span class="c1"># reshape [batch, 1, 28,28] to [batch, 28*28]</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="n">_</span><span class="p">,</span> <span class="n">h1</span> <span class="o">=</span> <span class="n">model1</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
                <span class="n">h1_clone</span> <span class="o">=</span> <span class="n">h1</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
                        
            <span class="n">out3</span> <span class="o">=</span> <span class="n">model3</span><span class="p">(</span><span class="n">h1_clone</span><span class="p">)</span> <span class="c1"># 49 -&gt; 784</span>
            <span class="n">loss3</span> <span class="o">=</span> <span class="n">criterion3</span><span class="p">(</span><span class="n">out3</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
            
            <span class="n">opt3</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">loss3</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">opt3</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="c1"># validation</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">losses</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">test_loader</span><span class="p">):</span>
                <span class="n">batch_weight</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">/</span><span class="n">batch_size</span>
                <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">_</span><span class="p">,</span> <span class="n">h1</span> <span class="o">=</span> <span class="n">model1</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
                <span class="n">out3</span> <span class="o">=</span> <span class="n">model3</span><span class="p">(</span><span class="n">h1</span><span class="p">)</span>
                <span class="n">loss3</span> <span class="o">=</span> <span class="n">criterion3</span><span class="p">(</span><span class="n">out3</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span><span class="o">*</span><span class="n">batch_weight</span>
                <span class="n">losses</span> <span class="o">+=</span> <span class="n">loss3</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                <span class="n">count</span> <span class="o">+=</span> <span class="mi">1</span>
                
        <span class="n">losses</span> <span class="o">=</span> <span class="n">losses</span><span class="o">/</span><span class="n">count</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epoch [</span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">epo_n</span><span class="si">}</span><span class="s2">], loss: </span><span class="si">{</span><span class="n">losses</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">### data visualization</span>

<span class="c1"># represent activation histogram</span>
<span class="k">def</span> <span class="nf">vis1</span><span class="p">(</span><span class="n">m1</span><span class="p">,</span> <span class="n">m2</span><span class="p">,</span> <span class="n">top_Nth_threshold</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        
        <span class="c1"># Collecting data # lin model</span>
        <span class="k">for</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">)</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">h1</span> <span class="o">=</span> <span class="n">m1</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
            
            <span class="k">if</span> <span class="n">batch_idx</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">target_h1</span> <span class="o">=</span> <span class="n">h1</span> <span class="c1"># [60,000,49]</span>
                <span class="n">target_class</span> <span class="o">=</span> <span class="n">targets</span> <span class="c1"># [60,000]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">target_h1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">target_h1</span><span class="p">,</span><span class="n">h1</span><span class="p">))</span>
                <span class="n">target_class</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">target_class</span><span class="p">,</span><span class="n">targets</span><span class="p">))</span>
    
        <span class="c1"># Collecting data # sae model</span>
        <span class="n">reconstruct_target_h1</span><span class="p">,</span> <span class="n">h2_large_dim</span> <span class="o">=</span> <span class="n">m2</span><span class="p">(</span><span class="n">target_h1</span><span class="p">)</span>
        
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">target_h1</span><span class="p">)):</span>
            <span class="c1"># Collecting data # original loss</span>
            <span class="n">tmp</span> <span class="o">=</span> <span class="n">m2</span><span class="o">.</span><span class="n">loss_function</span><span class="p">(</span><span class="n">reconstruct_target_h1</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">target_h1</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">h2_large_dim</span><span class="p">[</span><span class="n">i</span><span class="p">])</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">target_loss2_orig</span> <span class="o">=</span> <span class="n">tmp</span> <span class="c1"># [60,000]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">target_loss2_orig</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">target_loss2_orig</span><span class="p">,</span><span class="n">tmp</span><span class="p">))</span>
                
        <span class="c1"># m2_step1 = m2.encoder</span>
        <span class="n">m2_step2</span> <span class="o">=</span> <span class="n">m2</span><span class="o">.</span><span class="n">decoder</span>
    
        <span class="n">fig_c</span><span class="p">,</span> <span class="n">ax_c</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">num_classes</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
        <span class="c1"># digit class 0-9 (+scrambled)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_classes</span><span class="p">):</span>
            <span class="c1"># a digit class specific</span>
            <span class="n">class_mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">target_class</span><span class="o">==</span><span class="n">i</span><span class="p">)</span>
            <span class="n">target_h1_class</span> <span class="o">=</span> <span class="n">target_h1</span><span class="p">[</span><span class="n">class_mask</span><span class="p">]</span> <span class="c1"># target hidden net [class_sample,49]</span>
            <span class="n">gen_target_h1_class</span> <span class="o">=</span> <span class="n">reconstruct_target_h1</span><span class="p">[</span><span class="n">class_mask</span><span class="p">]</span> <span class="c1"># gen h1 [class_sample,49]</span>
            <span class="n">h2_large_dim_class</span> <span class="o">=</span> <span class="n">h2_large_dim</span><span class="p">[</span><span class="n">class_mask</span><span class="p">]</span> <span class="c1"># larger dim than h1 [class_sample,49*n]</span>
            <span class="n">target_loss2_orig_class</span> <span class="o">=</span> <span class="n">target_loss2_orig</span><span class="p">[</span><span class="n">class_mask</span><span class="p">]</span> <span class="c1"># original loss [class_sample]</span>
            
            <span class="c1"># Importance and xy2d coord calculation        </span>
            <span class="n">sample_size</span><span class="p">,</span> <span class="n">large_model_dim</span> <span class="o">=</span> <span class="n">h2_large_dim_class</span><span class="o">.</span><span class="n">shape</span>
            <span class="n">importance</span> <span class="o">=</span> <span class="p">[]</span>
            
            <span class="k">for</span> <span class="n">one_dim</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">large_model_dim</span><span class="p">):</span>
                <span class="c1"># importance</span>
                <span class="n">h2_class_perturb</span> <span class="o">=</span> <span class="n">h2_large_dim_class</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
                <span class="n">h2_class_perturb</span><span class="p">[:,</span><span class="n">one_dim</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>
                <span class="n">gen_h2_class_perturb</span> <span class="o">=</span> <span class="n">m2_step2</span><span class="p">(</span><span class="n">h2_class_perturb</span><span class="p">)</span>
                <span class="n">loss2_class_perturb</span> <span class="o">=</span> <span class="n">m2</span><span class="o">.</span><span class="n">loss_function</span><span class="p">(</span><span class="n">gen_h2_class_perturb</span><span class="p">,</span> <span class="n">target_h1_class</span><span class="p">,</span> <span class="n">h2_class_perturb</span><span class="p">)</span>
                <span class="n">importance</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss2_class_perturb</span> <span class="o">-</span> <span class="n">target_loss2_orig_class</span><span class="p">)</span>
                
            <span class="c1"># reduce dim from [large_dim, class_sample] to [large_dim]</span>
            <span class="n">importance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">importance</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">importance</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="c1"># calculate importance according to contribution to MSE loss</span>
            <span class="n">importance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">imp</span><span class="o">/</span><span class="nb">sum</span><span class="p">(</span><span class="n">importance</span><span class="p">)</span> <span class="k">for</span> <span class="n">imp</span> <span class="ow">in</span> <span class="n">importance</span><span class="p">])</span>
            <span class="c1"># importance[importance&lt;(1/large_model_dim)] = 0.0 # convert importance lower than expected contribution into 0</span>
            <span class="n">importance_norm</span> <span class="o">=</span> <span class="p">(</span><span class="n">importance</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">importance</span><span class="p">))</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">importance</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">importance</span><span class="p">))</span> <span class="c1"># normalize value into 0-1 range</span>
            <span class="c1"># Sort the columns of &#39;a&#39; based on importance</span>
            <span class="n">sorted_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">importance_norm</span><span class="p">)[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span> <span class="c1"># Get indices that would sort the importance array</span>
    
            <span class="n">top_Nth_thr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">importance</span><span class="p">,</span> <span class="n">top_Nth_threshold</span><span class="p">)</span>
            
            <span class="n">ax_c</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">importance</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;dashed&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">1</span><span class="p">);</span>
            <span class="n">ax_c</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">top_Nth_thr</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;orange&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;dashed&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">1</span><span class="p">);</span>
            <span class="n">ax_c</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">importance</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">);</span>
            <span class="n">ax_c</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">title</span><span class="o">.</span><span class="n">set_text</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
            <span class="n">ax_c</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;activation level&#39;</span><span class="p">)</span>
            
        <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">();</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">();</span>
    
        <span class="c1"># all classes combined</span>
        <span class="n">target_loss2_orig2</span> <span class="o">=</span> <span class="n">m2</span><span class="o">.</span><span class="n">loss_function</span><span class="p">(</span><span class="n">reconstruct_target_h1</span><span class="p">,</span> <span class="n">target_h1</span><span class="p">,</span> <span class="n">h2_large_dim</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">importance</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">large_dim_feat_repre</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">one_dim</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">large_model_dim</span><span class="p">):</span>
            <span class="c1"># importance</span>
            <span class="n">h2_perturb</span> <span class="o">=</span> <span class="n">h2_large_dim</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
            <span class="n">h2_perturb</span><span class="p">[:,</span><span class="n">one_dim</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>
            <span class="n">gen_h2_perturb</span> <span class="o">=</span> <span class="n">m2_step2</span><span class="p">(</span><span class="n">h2_perturb</span><span class="p">)</span>
            <span class="n">loss2_perturb</span> <span class="o">=</span> <span class="n">m2</span><span class="o">.</span><span class="n">loss_function</span><span class="p">(</span><span class="n">gen_h2_perturb</span><span class="p">,</span> <span class="n">target_h1</span><span class="p">,</span> <span class="n">h2_perturb</span><span class="p">)</span>
            <span class="n">importance</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss2_perturb</span> <span class="o">-</span> <span class="n">target_loss2_orig2</span><span class="p">)</span>
    
            <span class="c1"># represent h2</span>
            <span class="n">h2_perturb_zeros</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">h2_large_dim</span><span class="p">)</span>
            <span class="n">h2_perturb_zeros</span><span class="p">[:,</span><span class="n">one_dim</span><span class="p">]</span> <span class="o">=</span> <span class="n">h2_large_dim</span><span class="p">[:,</span><span class="n">one_dim</span><span class="p">]</span>
            <span class="n">gen_h2_perturb_zeros</span> <span class="o">=</span> <span class="n">m2_step2</span><span class="p">(</span><span class="n">h2_perturb_zeros</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">large_dim_feat_repre</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">gen_h2_perturb_zeros</span><span class="p">)</span>
            
        <span class="c1"># reduce dim from [large_dim, class_sample] to [large_dim]</span>
        <span class="n">importance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">importance</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">importance</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="c1"># calculate importance according to contribution to MSE loss</span>
        <span class="n">importance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">imp</span><span class="o">/</span><span class="nb">sum</span><span class="p">(</span><span class="n">importance</span><span class="p">)</span> <span class="k">for</span> <span class="n">imp</span> <span class="ow">in</span> <span class="n">importance</span><span class="p">])</span>
        <span class="c1"># importance[importance&lt;(1/large_model_dim)] = 0.0 # convert importance lower than expected contribution into 0</span>
        <span class="n">importance_norm</span> <span class="o">=</span> <span class="p">(</span><span class="n">importance</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">importance</span><span class="p">))</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">importance</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">importance</span><span class="p">))</span> <span class="c1"># normalize value into 0-1 range</span>
        <span class="c1"># Sort the columns of &#39;a&#39; based on importance</span>
        <span class="n">sorted_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">importance_norm</span><span class="p">)[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span> <span class="c1"># Get indices that would sort the importance array</span>
    
        <span class="n">top_Nth_thr2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">importance</span><span class="p">,</span> <span class="n">top_Nth_threshold</span><span class="p">)</span>
        
        <span class="n">fig_c2</span><span class="p">,</span> <span class="n">ax_c2</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
        <span class="n">ax_c2</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">importance</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;dashed&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">1</span><span class="p">);</span>
        <span class="n">ax_c2</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">top_Nth_thr2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;orange&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;dashed&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">1</span><span class="p">);</span>
        <span class="n">ax_c2</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">importance</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">);</span>
        <span class="n">ax_c2</span><span class="o">.</span><span class="n">title</span><span class="o">.</span><span class="n">set_text</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;all classes combined&#39;</span><span class="p">)</span>
        <span class="n">ax_c2</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;activation level&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">();</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">();</span>

<span class="c1"># represent reconstructed images, cosine similarity matrices between reconstructed images, etc</span>
<span class="k">def</span> <span class="nf">vis2</span><span class="p">(</span><span class="n">m1</span><span class="p">,</span> <span class="n">m2</span><span class="p">,</span> <span class="n">m3</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        
        <span class="c1"># Collecting data # lin model</span>
        <span class="k">for</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
    
            <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">)</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">h1</span> <span class="o">=</span> <span class="n">m1</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
            
            <span class="k">if</span> <span class="n">batch_idx</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">target_h1</span> <span class="o">=</span> <span class="n">h1</span> <span class="c1"># [60,000,49]</span>
                <span class="n">target_class</span> <span class="o">=</span> <span class="n">targets</span> <span class="c1"># [60,000]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">target_h1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">target_h1</span><span class="p">,</span><span class="n">h1</span><span class="p">))</span>
                <span class="n">target_class</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">target_class</span><span class="p">,</span><span class="n">targets</span><span class="p">))</span>
    
        <span class="c1"># Collecting data # ae model</span>
        <span class="n">reconstruct_target_h1</span><span class="p">,</span> <span class="n">h2_large_dim</span> <span class="o">=</span> <span class="n">m2</span><span class="p">(</span><span class="n">target_h1</span><span class="p">)</span>
        
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">target_h1</span><span class="p">)):</span>
            <span class="c1"># Collecting data # original loss</span>
            <span class="n">tmp</span> <span class="o">=</span> <span class="n">m2</span><span class="o">.</span><span class="n">loss_function</span><span class="p">(</span><span class="n">reconstruct_target_h1</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">target_h1</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">h2_large_dim</span><span class="p">[</span><span class="n">i</span><span class="p">])</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">target_loss2_orig</span> <span class="o">=</span> <span class="n">tmp</span> <span class="c1"># [60,000]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">target_loss2_orig</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">target_loss2_orig</span><span class="p">,</span><span class="n">tmp</span><span class="p">))</span>
                
        <span class="c1"># m2_step1 = m2.encoder</span>
        <span class="n">m2_step2</span> <span class="o">=</span> <span class="n">m2</span><span class="o">.</span><span class="n">decoder</span>
    
        <span class="n">importance_class</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="c1"># digit class 0-9 (+scrambled)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_classes</span><span class="p">):</span>
            <span class="c1"># a digit class specific</span>
            <span class="n">class_mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">target_class</span><span class="o">==</span><span class="n">i</span><span class="p">)</span>
            <span class="n">target_h1_class</span> <span class="o">=</span> <span class="n">target_h1</span><span class="p">[</span><span class="n">class_mask</span><span class="p">]</span> <span class="c1"># target hidden net [class_sample,49]</span>
            <span class="n">gen_target_h1_class</span> <span class="o">=</span> <span class="n">reconstruct_target_h1</span><span class="p">[</span><span class="n">class_mask</span><span class="p">]</span> <span class="c1"># gen h1 [class_sample,49]</span>
            <span class="n">h2_large_dim_class</span> <span class="o">=</span> <span class="n">h2_large_dim</span><span class="p">[</span><span class="n">class_mask</span><span class="p">]</span> <span class="c1"># larger dim than h1 [class_sample,49*n]</span>
            <span class="n">target_loss2_orig_class</span> <span class="o">=</span> <span class="n">target_loss2_orig</span><span class="p">[</span><span class="n">class_mask</span><span class="p">]</span> <span class="c1"># original loss [class_sample]</span>
            
            <span class="c1"># Importance and xy2d coord calculation        </span>
            <span class="n">sample_size</span><span class="p">,</span> <span class="n">large_model_dim</span> <span class="o">=</span> <span class="n">h2_large_dim_class</span><span class="o">.</span><span class="n">shape</span>
            <span class="n">importance</span> <span class="o">=</span> <span class="p">[]</span>
            
            <span class="k">for</span> <span class="n">one_dim</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">large_model_dim</span><span class="p">):</span>
                <span class="c1"># importance</span>
                <span class="n">h2_class_perturb</span> <span class="o">=</span> <span class="n">h2_large_dim_class</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
                <span class="n">h2_class_perturb</span><span class="p">[:,</span><span class="n">one_dim</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>
                <span class="n">gen_h2_class_perturb</span> <span class="o">=</span> <span class="n">m2_step2</span><span class="p">(</span><span class="n">h2_class_perturb</span><span class="p">)</span>
                <span class="n">loss2_class_perturb</span> <span class="o">=</span> <span class="n">m2</span><span class="o">.</span><span class="n">loss_function</span><span class="p">(</span><span class="n">gen_h2_class_perturb</span><span class="p">,</span> <span class="n">target_h1_class</span><span class="p">,</span> <span class="n">h2_class_perturb</span><span class="p">)</span>
                <span class="n">importance</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss2_class_perturb</span> <span class="o">-</span> <span class="n">target_loss2_orig_class</span><span class="p">)</span>
                
            <span class="c1"># reduce dim from [large_dim, class_sample] to [large_dim]</span>
            <span class="n">importance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">importance</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">importance</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="c1"># calculate importance according to contribution to MSE loss</span>
            <span class="n">importance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">imp</span><span class="o">/</span><span class="nb">sum</span><span class="p">(</span><span class="n">importance</span><span class="p">)</span> <span class="k">for</span> <span class="n">imp</span> <span class="ow">in</span> <span class="n">importance</span><span class="p">])</span>
            <span class="c1"># importance[importance&lt;(1/large_model_dim)] = 0.0 # convert importance lower than expected contribution into 0</span>
            <span class="n">importance_norm</span> <span class="o">=</span> <span class="p">(</span><span class="n">importance</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">importance</span><span class="p">))</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">importance</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">importance</span><span class="p">))</span> <span class="c1"># normalize value into 0-1 range</span>
            <span class="c1"># Sort the columns of &#39;a&#39; based on importance</span>
            <span class="n">sorted_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">importance_norm</span><span class="p">)[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span> <span class="c1"># Get indices that would sort the importance array</span>
    
            <span class="n">importance_class</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">sorted_indices</span><span class="p">[:</span><span class="mi">30</span><span class="p">]</span>
            
            <span class="n">top90thr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">importance</span><span class="p">,</span> <span class="mi">90</span><span class="p">)</span>
    
        <span class="c1"># all classes combined</span>
        <span class="n">target_loss2_orig2</span> <span class="o">=</span> <span class="n">m2</span><span class="o">.</span><span class="n">loss_function</span><span class="p">(</span><span class="n">reconstruct_target_h1</span><span class="p">,</span> <span class="n">target_h1</span><span class="p">,</span> <span class="n">h2_large_dim</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">importance</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">large_dim_feat_repre</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">one_dim</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">large_model_dim</span><span class="p">):</span>
            <span class="c1"># importance</span>
            <span class="n">h2_perturb</span> <span class="o">=</span> <span class="n">h2_large_dim</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
            <span class="n">h2_perturb</span><span class="p">[:,</span><span class="n">one_dim</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>
            <span class="n">gen_h2_perturb</span> <span class="o">=</span> <span class="n">m2_step2</span><span class="p">(</span><span class="n">h2_perturb</span><span class="p">)</span>
            <span class="n">loss2_perturb</span> <span class="o">=</span> <span class="n">m2</span><span class="o">.</span><span class="n">loss_function</span><span class="p">(</span><span class="n">gen_h2_perturb</span><span class="p">,</span> <span class="n">target_h1</span><span class="p">,</span> <span class="n">h2_perturb</span><span class="p">)</span>
            <span class="n">importance</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss2_perturb</span> <span class="o">-</span> <span class="n">target_loss2_orig2</span><span class="p">)</span>
    
            <span class="c1"># represent h2</span>
            <span class="n">h2_perturb_zeros</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">h2_large_dim</span><span class="p">)</span>
            <span class="n">h2_perturb_zeros</span><span class="p">[:,</span><span class="n">one_dim</span><span class="p">]</span> <span class="o">=</span> <span class="n">h2_large_dim</span><span class="p">[:,</span><span class="n">one_dim</span><span class="p">]</span>
            <span class="n">gen_h2_perturb_zeros</span> <span class="o">=</span> <span class="n">m2_step2</span><span class="p">(</span><span class="n">h2_perturb_zeros</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">large_dim_feat_repre</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">gen_h2_perturb_zeros</span><span class="p">)</span>
            
        <span class="c1"># reduce dim from [large_dim, class_sample] to [large_dim]</span>
        <span class="n">importance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">importance</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">importance</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="c1"># calculate importance according to contribution to MSE loss</span>
        <span class="n">importance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">imp</span><span class="o">/</span><span class="nb">sum</span><span class="p">(</span><span class="n">importance</span><span class="p">)</span> <span class="k">for</span> <span class="n">imp</span> <span class="ow">in</span> <span class="n">importance</span><span class="p">])</span>
        <span class="c1"># importance[importance&lt;(1/large_model_dim)] = 0.0 # convert importance lower than expected contribution into 0</span>
        <span class="n">importance_norm</span> <span class="o">=</span> <span class="p">(</span><span class="n">importance</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">importance</span><span class="p">))</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">importance</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">importance</span><span class="p">))</span> <span class="c1"># normalize value into 0-1 range</span>
        <span class="c1"># Sort the columns of &#39;a&#39; based on importance</span>
        <span class="n">sorted_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">importance_norm</span><span class="p">)[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span> <span class="c1"># Get indices that would sort the importance array</span>
    
        <span class="n">importance_class</span><span class="p">[</span><span class="s2">&quot;all&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">sorted_indices</span><span class="p">[:</span><span class="mi">30</span><span class="p">]</span>
        <span class="n">top90thr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">importance</span><span class="p">,</span> <span class="mi">90</span><span class="p">)</span>
    
        <span class="c1"># gen class image</span>
        <span class="n">gen_img_feats_class</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_classes</span><span class="p">):</span>
            <span class="n">imp_each_class</span> <span class="o">=</span> <span class="n">importance_class</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">h2_perturb3</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">h2_large_dim</span><span class="p">)</span>
            <span class="n">h2_perturb3</span><span class="p">[:,</span><span class="n">imp_each_class</span><span class="p">]</span> <span class="o">=</span> <span class="n">h2_large_dim</span><span class="p">[:,</span><span class="n">imp_each_class</span><span class="p">]</span>
            <span class="n">gen_h2_perturb3</span> <span class="o">=</span> <span class="n">m2_step2</span><span class="p">(</span><span class="n">h2_perturb3</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">gen_img_feats_class</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">m3</span><span class="p">(</span><span class="n">gen_h2_perturb3</span><span class="p">))</span>
        <span class="n">gen_img_feats_class_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">gen_img_feats_class</span><span class="p">)</span>
    
        <span class="n">fig3</span><span class="p">,</span> <span class="n">ax3</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mf">3.5</span><span class="p">))</span>
        
        <span class="c1"># draw feat</span>
        <span class="n">large_dim_feat_repre_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">large_dim_feat_repre</span><span class="p">)</span> <span class="c1"># 98 feat x 49 latent dim</span>
        <span class="n">rep_normalized</span> <span class="o">=</span> <span class="n">large_dim_feat_repre_np</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">large_dim_feat_repre_np</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">rep_dot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">rep_normalized</span><span class="p">,</span> <span class="n">rep_normalized</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
        <span class="n">pos</span><span class="o">=</span><span class="n">ax3</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">rep_dot</span><span class="p">)</span>
        <span class="n">fig3</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">pos</span><span class="p">)</span>
        
        <span class="c1"># Compute the cosine distance matrix</span>
        <span class="n">cosine_distance_matrix</span> <span class="o">=</span> <span class="n">cosine_distances</span><span class="p">(</span><span class="n">rep_normalized</span><span class="p">)</span>
        <span class="c1"># Apply t-SNE to project into 2D space</span>
        <span class="n">tsne</span> <span class="o">=</span> <span class="n">TSNE</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s2">&quot;pca&quot;</span><span class="p">,</span> <span class="n">perplexity</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
        <span class="n">feat_repre_2d</span> <span class="o">=</span> <span class="n">tsne</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">cosine_distance_matrix</span><span class="p">)</span>
        <span class="n">ax3</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
        <span class="n">ax3</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
        <span class="n">ax3</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">feat_repre_2d</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="n">feat_repre_2d</span><span class="p">[:,</span><span class="mi">1</span><span class="p">])</span>
    
        <span class="c1"># select only important one</span>
        <span class="n">imp_uniq_class</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">importance_class</span><span class="p">:</span>
            <span class="n">imp_classes</span> <span class="o">=</span> <span class="n">importance_class</span><span class="p">[</span><span class="n">item</span><span class="p">][:</span><span class="mi">3</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">clss</span> <span class="ow">in</span> <span class="n">imp_classes</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">clss</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">imp_uniq_class</span><span class="p">:</span>
                    <span class="n">imp_uniq_class</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">clss</span><span class="p">)</span>
        <span class="n">select_feats</span> <span class="o">=</span> <span class="n">large_dim_feat_repre_np</span><span class="p">[</span><span class="n">imp_uniq_class</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">select_rep_normalized</span> <span class="o">=</span> <span class="n">select_feats</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">select_feats</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">select_rep_dot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">select_rep_normalized</span><span class="p">,</span> <span class="n">select_rep_normalized</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
        <span class="n">pos2</span><span class="o">=</span><span class="n">ax3</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">select_rep_dot</span><span class="p">)</span>
        <span class="n">fig3</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">pos2</span><span class="p">)</span>
    
        <span class="c1"># Compute the cosine distance matrix</span>
        <span class="n">select_cosine_distance_matrix</span> <span class="o">=</span> <span class="n">cosine_distances</span><span class="p">(</span><span class="n">select_rep_normalized</span><span class="p">)</span>
        <span class="c1"># Apply t-SNE to project into 2D space</span>
        <span class="c1"># tsne = TSNE(n_components=2, init=&quot;pca&quot;, perplexity=3, random_state=42)</span>
        <span class="n">select_feat_repre_2d</span> <span class="o">=</span> <span class="n">tsne</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">select_cosine_distance_matrix</span><span class="p">)</span>
        <span class="n">ax3</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
        <span class="n">ax3</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
        <span class="n">ax3</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">select_feat_repre_2d</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="n">select_feat_repre_2d</span><span class="p">[:,</span><span class="mi">1</span><span class="p">])</span>
    
        <span class="c1"># Add class labels as text</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">imp_uniq_class</span><span class="p">):</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">select_feat_repre_2d</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">ax3</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">y</span> <span class="o">+</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">)</span>
    
        <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    
        <span class="n">fig4</span><span class="p">,</span> <span class="n">ax4</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mf">3.5</span><span class="p">))</span>
        
        <span class="c1"># gen image</span>
        <span class="n">gen_img_perturb</span> <span class="o">=</span> <span class="n">m3</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">large_dim_feat_repre_np</span><span class="p">))</span>
    
        <span class="n">gen_img_perturb_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">gen_img_perturb</span><span class="p">)</span> <span class="c1"># 98 feat x 49 latent dim</span>
        <span class="n">rep_normalized2</span> <span class="o">=</span> <span class="n">gen_img_perturb_np</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">gen_img_perturb_np</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">rep_dot2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">rep_normalized2</span><span class="p">,</span> <span class="n">rep_normalized2</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
        <span class="n">pos3</span><span class="o">=</span><span class="n">ax4</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">rep_dot2</span><span class="p">)</span>
        <span class="n">fig4</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">pos3</span><span class="p">)</span>
    
        <span class="c1"># Compute the cosine distance matrix</span>
        <span class="n">cosine_distance_matrix2</span> <span class="o">=</span> <span class="n">cosine_distances</span><span class="p">(</span><span class="n">rep_normalized2</span><span class="p">)</span>
        <span class="c1"># Apply t-SNE to project into 2D space</span>
        <span class="c1"># tsne = TSNE(n_components=2, init=&quot;pca&quot;, perplexity=3, random_state=42)</span>
        <span class="n">feat_repre_2d2</span> <span class="o">=</span> <span class="n">tsne</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">cosine_distance_matrix2</span><span class="p">)</span>
        <span class="n">ax4</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
        <span class="n">ax4</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
        <span class="n">ax4</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">feat_repre_2d2</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="n">feat_repre_2d</span><span class="p">[:,</span><span class="mi">1</span><span class="p">])</span>
        
        <span class="n">select_feats2</span> <span class="o">=</span> <span class="n">gen_img_perturb_np</span><span class="p">[</span><span class="n">imp_uniq_class</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">select_feats_norm</span> <span class="o">=</span> <span class="n">select_feats2</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">select_feats2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">select_rep_dot2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">select_feats_norm</span><span class="p">,</span> <span class="n">select_feats_norm</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
        <span class="n">pos4</span><span class="o">=</span><span class="n">ax4</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">select_rep_dot2</span><span class="p">)</span>
        <span class="n">fig4</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">pos4</span><span class="p">)</span>
    
        <span class="c1"># Compute the cosine distance matrix</span>
        <span class="n">select_cosine_distance_matrix2</span> <span class="o">=</span> <span class="n">cosine_distances</span><span class="p">(</span><span class="n">select_feats_norm</span><span class="p">)</span>
        <span class="c1"># Apply t-SNE to project into 2D space</span>
        <span class="c1"># tsne = TSNE(n_components=2, init=&quot;pca&quot;, perplexity=3, random_state=42)</span>
        <span class="n">select_feat_repre_2d2</span> <span class="o">=</span> <span class="n">tsne</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">select_cosine_distance_matrix2</span><span class="p">)</span>
        <span class="n">ax4</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
        <span class="n">ax4</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
        <span class="n">ax4</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">select_feat_repre_2d2</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">select_feat_repre_2d2</span><span class="p">[:,</span><span class="mi">1</span><span class="p">])</span>
        
        <span class="c1"># Add class labels as text</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">imp_uniq_class</span><span class="p">):</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">select_feat_repre_2d2</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">ax4</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">y</span> <span class="o">+</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">)</span>
        
        <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
        
        <span class="c1">### </span>
        <span class="c1">### </span>
        <span class="c1">### </span>
        
        <span class="c1"># select_feats_n_class</span>
        <span class="n">gen_img_perturb_np_2d</span> <span class="o">=</span> <span class="n">gen_img_perturb_np</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">gen_img_perturb_np</span><span class="p">),</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">))</span>
        
        <span class="c1"># draw default size</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">select_feat_repre_2d2</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="n">select_feat_repre_2d2</span><span class="p">[:,</span><span class="mi">1</span><span class="p">])</span>
    
        <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>
            
        <span class="c1"># Add class labels as text</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">imp_uniq_class</span><span class="p">)):</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">select_feat_repre_2d2</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">add_image</span><span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="n">select_feats2</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">),</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="n">zoom</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">imp_uniq_class</span><span class="p">)):</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">select_feat_repre_2d2</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">x</span><span class="o">+</span><span class="mi">3</span><span class="p">,</span> <span class="n">y</span><span class="o">+</span><span class="mi">5</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;f</span><span class="si">{</span><span class="n">imp_uniq_class</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    
        <span class="c1"># check correlation between cosine similarity matrices</span>
        <span class="n">rep1_flat</span> <span class="o">=</span> <span class="n">select_cosine_distance_matrix</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
        <span class="n">rep2_flat</span> <span class="o">=</span> <span class="n">select_cosine_distance_matrix2</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
        
        <span class="n">correlation</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">corrcoef</span><span class="p">(</span><span class="n">rep1_flat</span><span class="p">,</span> <span class="n">rep2_flat</span><span class="p">)[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;correlation btw cos sim mat, </span><span class="si">{</span><span class="n">correlation</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    
        <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">gen_img_feats_class_np</span><span class="p">)):</span>
            <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">gen_img_feats_class_np</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">))</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;=</span> <span class="mi">9</span><span class="p">:</span>
                <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">title</span><span class="o">.</span><span class="n">set_text</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;class </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">title</span><span class="o">.</span><span class="n">set_text</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;scrambled&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
        
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;important feature indices for each class&quot;</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">importance_class</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;class </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">importance_class</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">epo1</span> <span class="o">=</span> <span class="mi">10</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Phase1.1: Train lin model&quot;</span><span class="p">);</span> 
<span class="n">phase1</span><span class="p">(</span><span class="n">m1</span><span class="p">,</span> <span class="n">criterion1</span><span class="p">,</span> <span class="n">opt1</span><span class="p">,</span> <span class="n">epo1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Phase1.1: Train lin model
Epoch [1/10], loss: 0.1877, accuracy: 0.9643
Epoch [2/10], loss: 0.0505, accuracy: 0.9724
Epoch [3/10], loss: 0.0686, accuracy: 0.9761
Epoch [4/10], loss: 0.1214, accuracy: 0.9787
Epoch [5/10], loss: 0.0527, accuracy: 0.9789
Epoch [6/10], loss: 0.0221, accuracy: 0.9803
Epoch [7/10], loss: 0.0606, accuracy: 0.9808
Epoch [8/10], loss: 0.0412, accuracy: 0.9804
Epoch [9/10], loss: 0.0517, accuracy: 0.9816
Epoch [10/10], loss: 0.0192, accuracy: 0.9815
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">epo2</span> <span class="o">=</span> <span class="mi">10</span>

<span class="c1"># variable parameters</span>
<span class="n">hidden_size2</span> <span class="o">=</span> <span class="mi">49</span><span class="o">*</span><span class="mi">2</span> <span class="c1"># for sae hidden dim</span>
<span class="n">lr2</span> <span class="o">=</span> <span class="mf">0.0001</span> <span class="c1"># lr for opt2 # 0.001, etc </span>
<span class="n">sparsity_lv</span> <span class="o">=</span> <span class="mf">0.1</span> <span class="c1"># 0.001(dense)~0.999(sparse)</span>
<span class="c1"># sparsity_impact = 1e-4 # 1e-4</span>
<span class="c1"># eps = 1e-7 # 1e-8 # epsilon</span>

<span class="c1"># encoder/decoder nets</span>
<span class="n">enc_m</span> <span class="o">=</span> <span class="n">encoderNN</span><span class="p">(</span><span class="n">input_size</span><span class="o">=</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="o">=</span><span class="n">hidden_size2</span><span class="p">)</span> <span class="c1"># 49 -&gt; 49*n</span>
<span class="n">dec_m</span> <span class="o">=</span> <span class="n">decoderNN</span><span class="p">(</span><span class="n">hidden_size</span><span class="o">=</span><span class="n">hidden_size2</span><span class="p">,</span> <span class="n">output_size</span><span class="o">=</span><span class="n">hidden_size</span><span class="p">)</span> <span class="c1"># 49*n -&gt; 49</span>

<span class="n">m2</span> <span class="o">=</span> <span class="n">sae_model</span><span class="p">(</span><span class="n">encoder</span><span class="o">=</span><span class="n">enc_m</span><span class="p">,</span> <span class="n">decoder</span><span class="o">=</span><span class="n">dec_m</span><span class="p">,</span> <span class="n">sparsity_lambda</span><span class="o">=</span><span class="n">sparsity_impact</span><span class="p">,</span> <span class="n">sparsity_target</span><span class="o">=</span><span class="n">sparsity_lv</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="n">eps</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">opt2</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">m2</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr2</span><span class="p">)</span> <span class="c1"># Optimizer</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Phase2: Train sae model&quot;</span><span class="p">);</span>
<span class="n">phase2</span><span class="p">(</span><span class="n">m1</span><span class="p">,</span> <span class="n">m2</span><span class="p">,</span> <span class="n">opt2</span><span class="p">,</span> <span class="n">epo2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Phase2: Train sae model
Epoch [1/10], loss-val: 0.0599
Epoch [2/10], loss-val: 0.0299
Epoch [3/10], loss-val: 0.0191
Epoch [4/10], loss-val: 0.0126
Epoch [5/10], loss-val: 0.0095
Epoch [6/10], loss-val: 0.0081
Epoch [7/10], loss-val: 0.0071
Epoch [8/10], loss-val: 0.0064
Epoch [9/10], loss-val: 0.0061
Epoch [10/10], loss-val: 0.0058
</pre></div>
</div>
</div>
</div>
<br>
<h4 id="Figure-1">Figure 1</h4>
<br><div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">top_nth_threshold</span> <span class="o">=</span> <span class="mi">90</span>
<span class="n">vis1</span><span class="p">(</span><span class="n">m1</span><span class="p">,</span> <span class="n">m2</span><span class="p">,</span> <span class="n">top_nth_threshold</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/87283783d8962d9ab5576336bb4d5e1eb254122e47b86d5ee0d8a1c622177b08.png" src="../_images/87283783d8962d9ab5576336bb4d5e1eb254122e47b86d5ee0d8a1c622177b08.png" />
<img alt="../_images/86c61a2defb811abaa85194064c97ef20335ebaf4fe218dfc9ed2658d125f66d.png" src="../_images/86c61a2defb811abaa85194064c97ef20335ebaf4fe218dfc9ed2658d125f66d.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">epo2</span> <span class="o">=</span> <span class="mi">10</span>

<span class="c1"># variable parameters</span>
<span class="n">hidden_size2</span> <span class="o">=</span> <span class="mi">49</span><span class="o">*</span><span class="mi">2</span> <span class="c1"># for sae hidden dim</span>
<span class="n">lr2</span> <span class="o">=</span> <span class="mf">0.0001</span> <span class="c1"># lr for opt2 # 0.001, etc </span>
<span class="n">sparsity_lv</span> <span class="o">=</span> <span class="mf">0.999</span> <span class="c1"># 0.001(dense)~0.999(sparse)</span>
<span class="c1"># sparsity_impact = 1e-4 # 1e-4</span>
<span class="c1"># eps = 1e-7 # 1e-8 # epsilon</span>

<span class="c1"># encoder/decoder nets</span>
<span class="n">enc_m</span> <span class="o">=</span> <span class="n">encoderNN</span><span class="p">(</span><span class="n">input_size</span><span class="o">=</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="o">=</span><span class="n">hidden_size2</span><span class="p">)</span> <span class="c1"># 49 -&gt; 49*n</span>
<span class="n">dec_m</span> <span class="o">=</span> <span class="n">decoderNN</span><span class="p">(</span><span class="n">hidden_size</span><span class="o">=</span><span class="n">hidden_size2</span><span class="p">,</span> <span class="n">output_size</span><span class="o">=</span><span class="n">hidden_size</span><span class="p">)</span> <span class="c1"># 49*n -&gt; 49</span>

<span class="n">m2</span> <span class="o">=</span> <span class="n">sae_model</span><span class="p">(</span><span class="n">encoder</span><span class="o">=</span><span class="n">enc_m</span><span class="p">,</span> <span class="n">decoder</span><span class="o">=</span><span class="n">dec_m</span><span class="p">,</span> <span class="n">sparsity_lambda</span><span class="o">=</span><span class="n">sparsity_impact</span><span class="p">,</span> <span class="n">sparsity_target</span><span class="o">=</span><span class="n">sparsity_lv</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="n">eps</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">opt2</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">m2</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr2</span><span class="p">)</span> <span class="c1"># Optimizer</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Phase2: Train sae model&quot;</span><span class="p">);</span>
<span class="n">phase2</span><span class="p">(</span><span class="n">m1</span><span class="p">,</span> <span class="n">m2</span><span class="p">,</span> <span class="n">opt2</span><span class="p">,</span> <span class="n">epo2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Phase2: Train sae model
Epoch [1/10], loss-val: 0.0770
Epoch [2/10], loss-val: 0.0349
Epoch [3/10], loss-val: 0.0127
Epoch [4/10], loss-val: 0.0050
Epoch [5/10], loss-val: 0.0041
Epoch [6/10], loss-val: 0.0044
Epoch [7/10], loss-val: 0.0052
Epoch [8/10], loss-val: 0.0057
Epoch [9/10], loss-val: 0.0059
Epoch [10/10], loss-val: 0.0061
</pre></div>
</div>
</div>
</div>
<br>
<h4 id="Figure-2">Figure 2</h4>
<br><div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">top_nth_threshold</span> <span class="o">=</span> <span class="mi">90</span>
<span class="n">vis1</span><span class="p">(</span><span class="n">m1</span><span class="p">,</span> <span class="n">m2</span><span class="p">,</span> <span class="n">top_nth_threshold</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/9ef23fa648fadf87ef23ac4f056859908de01aa57dd077c1c640ea932e655e7e.png" src="../_images/9ef23fa648fadf87ef23ac4f056859908de01aa57dd077c1c640ea932e655e7e.png" />
<img alt="../_images/9b5a3f791f529a2e0635cabedd3f975bee4d245f7df9d859198fdae68ab80ca2.png" src="../_images/9b5a3f791f529a2e0635cabedd3f975bee4d245f7df9d859198fdae68ab80ca2.png" />
</div>
</div>
<p><br><br></p>
</section>
<section id="exp3-2-result">
<h2>Exp3.2. Result<a class="headerlink" href="#exp3-2-result" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>these above graphs are histograms of activation level (x-axis) of each neuron responding to each digit input.</p></li>
<li><p>the “10” class is randomly scrambled digit inputs, which should be ignored, aiming to enhance to ignore background images.</p></li>
<li><p>the black dotted vertical line indicates mean activation level.</p></li>
<li><p>the organge dotted vertical line indicates the top 90th percentile activation level.</p></li>
<li><p>when sparsity level is set to 0.1, only a few neuron is largely activated, and the rest of neurons are not activated much.</p></li>
<li><p>in contrast, when sparsity level is set to 0.999, neuron activations are widely distributed.</p></li>
<li><p>yet, it is unclear from these results how these distributed neuron activations contribute to representation of actual digit images.</p></li>
</ul>
<br>
<br>
</section>
<section id="exp3-3-run-second-exp">
<h2>Exp3.3. Run second exp<a class="headerlink" href="#exp3-3-run-second-exp" title="Link to this heading">#</a></h2>
<p>Accordingly, the second exp aims to reconstruct actual digit images from the widely distributed neuron activations.</p>
<p>More specific questions are:</p>
<p>The core questions:</p>
<ul class="simple">
<li><p>merely activating specific neurons in the hidden layer of the lin model can reconstruct human-tangible images?</p></li>
<li><p>even though neuron activations are widely distributed when sparsity level is large, does a specific collection of neurons represent a specific digit image?</p></li>
<li><p>are there any difficulties representing specific digit images?</p></li>
</ul>
<p>The feature structures:</p>
<ul class="simple">
<li><p>what are relationships between the original neurons in the hidden layer of the lin model? (1)</p></li>
<li><p>What are relationships between the reconstructed images? (2)</p></li>
<li><p>Is the (1) and the (2) correlated, or completely different relationships?</p></li>
</ul>
<p><br><br></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">epo3</span> <span class="o">=</span> <span class="mi">10</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Phase3.1: Train img gen model&quot;</span><span class="p">);</span> 
<span class="n">phase3</span><span class="p">(</span><span class="n">m1</span><span class="p">,</span> <span class="n">m3</span><span class="p">,</span> <span class="n">criterion3</span><span class="p">,</span> <span class="n">opt3</span><span class="p">,</span> <span class="n">epo3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Phase3.1: Train img gen model
Epoch [1/10], loss: 0.0837
Epoch [2/10], loss: 0.0765
Epoch [3/10], loss: 0.0730
Epoch [4/10], loss: 0.0710
Epoch [5/10], loss: 0.0697
Epoch [6/10], loss: 0.0689
Epoch [7/10], loss: 0.0683
Epoch [8/10], loss: 0.0678
Epoch [9/10], loss: 0.0674
Epoch [10/10], loss: 0.0670
</pre></div>
</div>
</div>
</div>
<br>
<h4 id="Figure-3">Figure 3</h4>
<br><div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">vis2</span><span class="p">(</span><span class="n">m1</span><span class="p">,</span> <span class="n">m2</span><span class="p">,</span> <span class="n">m3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/926b98bcb10d9da0a63d271370738ba0a2ecf33ee00d1f085c75db9c7ba65419.png" src="../_images/926b98bcb10d9da0a63d271370738ba0a2ecf33ee00d1f085c75db9c7ba65419.png" />
<img alt="../_images/f5d6bb6e055a453ab36504910247d09436ec862fbcfeb7ab9ce6e5805ea4a0ce.png" src="../_images/f5d6bb6e055a453ab36504910247d09436ec862fbcfeb7ab9ce6e5805ea4a0ce.png" />
<img alt="../_images/2110bf80dc6d62582f79f4348c940a15eb9129205733aa7ef2f2242410d68dd0.png" src="../_images/2110bf80dc6d62582f79f4348c940a15eb9129205733aa7ef2f2242410d68dd0.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>correlation btw cos sim mat, 0.6554962153023876
</pre></div>
</div>
<img alt="../_images/559a7a1a408e54839069a85a178bac0a655d80666123549dbe3029322fc98fc9.png" src="../_images/559a7a1a408e54839069a85a178bac0a655d80666123549dbe3029322fc98fc9.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>important feature indices for each class
class 0: [67 17 77  2 55 92 68 72 18 89 60 20 96 56 52 21 38 27 30 86 50 66 83 29
 73 54 97 88  3 23]
class 1: [95 75 88 76 14  6 23 20 52 61 63 15 21 60 83 90 97 46 19 84 54  8 47 80
 37 29 44 96 85 66]
class 2: [88 20 63 52 92 66 17 85 95 83 60 59  6 55 51 28 97 37 96 80 45 14  8 94
 38  4  7 77 30 21]
class 3: [67  6 95 28 33 66 38 88 54 24 92 56 17 60 72 80 96 41 20 37  7  2 23 25
 64 63 62 75 27 30]
class 4: [96 38 51 84 74 87 67  0 32 63 66 54 30 60 47 76 18  2 37 75 77  6 29 55
  8 40 93 83 28 61]
class 5: [67  2 89 95 55 54 38 21 14 28 29 18  0 72 92  8 52 77 56 83 59 66 80 88
 87 90  9 40 73 23]
class 6: [83 88 89 51  0 60 55 18 66  8 63 38 14 67 21  2 57  4 45 28 52 96 74 17
 61 47 23 94  3 77]
class 7: [ 6 75 96 20 84 38 95 63 55 72 67 30 90 97 18 51 52 47 50 56 66  8 87 37
  5 85 77 76 61 83]
class 8: [95 77 38 89 80 66 67 51 52 61 54 14  0 60 29 20  2 88 84 28 63 17 75 72
  6 83 76 87 85 40]
class 9: [96 38 95 67  6 51 77  8 97 87 84 75 72 74 32 60 29 27 76 37 20 66 89 56
 61 47 30 26 64  2]
class 10: [15 25 84 28 47 67 93 69 30 55 36 76  6 97 79 61 48 63 65 66 50 14 74 62
 94  9 29 72 20 21]
class all: [15 67 84 28  6 25 47 55 30 76 66 97 93 63 69 61 20 14 36 29 72 74 21 51
 96 50 95 88 87 60]
</pre></div>
</div>
</div>
</div>
<p><br><br></p>
</section>
<section id="exp3-4-result">
<h2>Exp3.4. Result<a class="headerlink" href="#exp3-4-result" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>the first row demonstrates cosine similarity matrices of reconstructed hidden layer neurons (the 1st and the 3rd columns) and feature structures in 2D (reducing dim by tsne data transformation).</p></li>
<li><p>the second row demonstrates cosine similarity matrices of reconstructed images from the reconstructed hidden layer neurons.</p></li>
<li><p>the 3rd and the 4th columns are represenations of the top 2 important features for each digit 0-9 + scrambled image.</p></li>
<li><p>the 3rd row, I added the reconstructed images from selective features with feature number next to images.</p></li>
<li><p>the final figure is each of reconstructed digit images from the reconstructed hidden layer neurons.</p>
<ul>
<li><p>interestingly, some digits are reconstructed well (e.g. 0, 1, 2, 3, 7, 9), while others are struggling to reconstruct (e.g. 4, 8).</p></li>
<li><p>interestingly, struggling digits are similar to the other digits (e.g. 8 vs 9), which might be a hint to reconstruct the nuance of the digit images.</p></li>
</ul>
</li>
<li><p>interestingly, structures across reconstructed hidden layer neurons and structures across reconstructed images are highly correlated (0.6554962153023876).</p>
<ul>
<li><p>does it mean that data distributions are similar based on physical features and mentally represented features?</p>
<ul>
<li><p>in fact, digit images are extracted products from human internal representations or abstracted concepts, so it would be interesting to see if naturally existied objects will show similar patterns.</p></li>
</ul>
</li>
</ul>
</li>
</ul>
<p><br><br></p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./nb"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="notebook2.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Experiment 2</p>
      </div>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exp3">Exp3</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exp3-0-prepare-packages">Exp3.0. Prepare packages</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exp3-1-run-first-exp">Exp3.1. Run first exp</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exp3-2-result">Exp3.2. Result</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exp3-3-run-second-exp">Exp3.3. Run second exp</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exp3-4-result">Exp3.4. Result</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By The Jupyter Book Community
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549"></script>
<script defer src="../_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>